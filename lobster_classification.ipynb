{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f355948179877e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T19:33:43.992067Z",
     "start_time": "2024-03-28T19:33:42.917733Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Matplotlib requires numpy>=1.20; you have 1.19.2",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mopen_clip\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mipyplot\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m figure, imshow, axis\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m imread\n",
      "File \u001B[0;32m~/anaconda3/envs/diffvr3/lib/python3.8/site-packages/matplotlib/__init__.py:227\u001B[0m\n\u001B[1;32m    222\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m parse_version(module\u001B[38;5;241m.\u001B[39m__version__) \u001B[38;5;241m<\u001B[39m parse_version(minver):\n\u001B[1;32m    223\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMatplotlib requires \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m>=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mminver\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m; \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    224\u001B[0m                               \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou have \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule\u001B[38;5;241m.\u001B[39m__version__\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 227\u001B[0m \u001B[43m_check_versions\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    230\u001B[0m \u001B[38;5;66;03m# The decorator ensures this always returns the same handler (and it is only\u001B[39;00m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;66;03m# attached once).\u001B[39;00m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mlru_cache()\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_ensure_handler\u001B[39m():\n",
      "File \u001B[0;32m~/anaconda3/envs/diffvr3/lib/python3.8/site-packages/matplotlib/__init__.py:223\u001B[0m, in \u001B[0;36m_check_versions\u001B[0;34m()\u001B[0m\n\u001B[1;32m    221\u001B[0m module \u001B[38;5;241m=\u001B[39m importlib\u001B[38;5;241m.\u001B[39mimport_module(modname)\n\u001B[1;32m    222\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m parse_version(module\u001B[38;5;241m.\u001B[39m__version__) \u001B[38;5;241m<\u001B[39m parse_version(minver):\n\u001B[0;32m--> 223\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMatplotlib requires \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m>=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mminver\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m; \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    224\u001B[0m                       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou have \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule\u001B[38;5;241m.\u001B[39m__version__\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mImportError\u001B[0m: Matplotlib requires numpy>=1.20; you have 1.19.2"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import open_clip\n",
    "import ipyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.pyplot import figure, imshow, axis\n",
    "from matplotlib.image import imread\n",
    "\n",
    "torch.set_printoptions(precision=3, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf62eb4b5ccce31",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def showImagesHorizontally(list_of_files):\n",
    "    fig = figure()\n",
    "    number_of_files = len(list_of_files)\n",
    "    for i in range(number_of_files):\n",
    "        a=fig.add_subplot(1,number_of_files,i+1)\n",
    "        image = imread(list_of_files[i])\n",
    "        # imshow(image, cmap='Greys_r')\n",
    "        imshow(image)\n",
    "        axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745863dbd0be0b37",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1964b4ebc2e979c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c227598fc334509",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "open_clip.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c4607bb3290ee1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_b, _, preprocess_b = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')\n",
    "tokenizer_b = open_clip.get_tokenizer('ViT-B-32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15decfd0ec2d296",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_l, _, preprocess_l = open_clip.create_model_and_transforms('ViT-L-14-336', pretrained='openai')\n",
    "tokenizer_l = open_clip.get_tokenizer('ViT-B-32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f110565a37ea9aaa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_b = tokenizer_b([\"a diagram\", \"a lobster\", \"a cat\"])\n",
    "text_l = tokenizer_l([\"a diagram\", \"a lobster\", \"a cat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa79572c2d6eda92",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Show Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f58dd2fcd5b5797",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<div style=\"display: flex; flex-direction: row;\">\n",
    "    <img src=\"./experiment_data/lobster_grayscale_0.png\" style=\"width: 200px; height: auto; margin-right: 10px;\">\n",
    "    <img src=\"./experiment_data/lobster_blue_0.png\" style=\"width: 200px; height: auto; margin-right: 10px;\">\n",
    "    <img src=\"./experiment_data/lobster_red_0.png\" style=\"width: 200px; height: auto; margin-right: 10px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30340b8745aa51d0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lobster_0_files = [\n",
    "    \"./experiment_data/lobster_grayscale_0.png\",\n",
    "    \"./experiment_data/lobster_blue_0.png\",\n",
    "    \"./experiment_data/lobster_red_0.png\"\n",
    "]\n",
    "\n",
    "lobster_1_files = [\n",
    "    \"./experiment_data/lobster_grayscale_1.png\",\n",
    "    \"./experiment_data/lobster_blue_1.png\",\n",
    "    \"./experiment_data/lobster_red_1.png\"\n",
    "]\n",
    "\n",
    "lobster_2_files = [\n",
    "    \"./experiment_data/lobster_grayscale_2.png\",\n",
    "    \"./experiment_data/lobster_blue_2.png\",\n",
    "    \"./experiment_data/lobster_red_2.png\"\n",
    "]\n",
    "\n",
    "lobster_real_files = [\n",
    "    \"./experiment_data/rlobster_0.png\",\n",
    "    \"./experiment_data/rlobster_1.png\",\n",
    "    \"./experiment_data/rlobster_2.png\"\n",
    "    \"./experiment_data/rlobster_3.png\"\n",
    "    \"./experiment_data/rlobster_4.png\"\n",
    "]\n",
    "\n",
    "# showImagesHorizontally(lobster_0_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212bfc737f603e3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Lobster (Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c877f8a49f5f260",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ipyplot.plot_images(lobster_0_files, max_images=3, img_width=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3856147d6014cc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Lobster (Front)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59359a33825892c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ipyplot.plot_images(lobster_1_files, max_images=3, img_width=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb30a979bebb7eaf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Lobster (Bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e0669616a90b48",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ipyplot.plot_images(lobster_2_files, max_images=3, img_width=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lobster Images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdfafda13c0a1dc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ipyplot.plot_images(lobster_real_files, max_images=5, img_width=250)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88caf55af643b7fd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in lobster_0_files:\n",
    "    image = preprocess_b(Image.open(filepath)).unsqueeze(0)\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        image_features = model_b.encode_image(image)\n",
    "        text_features = model_b.encode_text(text_b)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        dist = image_features @ text_features.T\n",
    "        cos_sim = dist / (torch.norm(image_features, dim=-1) * torch.norm(text_features, dim=-1))\n",
    "        text_probs = (100.0 * dist).softmax(dim=-1)\n",
    "    \n",
    "    print(\"Image: \", filepath.split(\"/\")[-1])\n",
    "    print(f\"Label probs: {text_probs}\")\n",
    "    print(f\"Cosine similarity: {cos_sim}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24356dfb22db8e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for filepath in lobster_1_files:\n",
    "    image = preprocess_b(Image.open(filepath)).unsqueeze(0)\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        image_features = model_b.encode_image(image)\n",
    "        text_features = model_b.encode_text(text_b)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        dist = image_features @ text_features.T\n",
    "        cos_sim = dist / (torch.norm(image_features, dim=-1) * torch.norm(text_features, dim=-1))\n",
    "        text_probs = (100.0 * dist).softmax(dim=-1)\n",
    "    \n",
    "    print(\"Image: \", filepath.split(\"/\")[-1])\n",
    "    print(f\"Label probs: {text_probs}\")\n",
    "    print(f\"Cosine similarity: {cos_sim}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8576599afde98f7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for filepath in lobster_2_files:\n",
    "    image = preprocess_b(Image.open(filepath)).unsqueeze(0)\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        image_features = model_b.encode_image(image)\n",
    "        text_features = model_b.encode_text(text_b)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        dist = image_features @ text_features.T\n",
    "        cos_sim = dist / (torch.norm(image_features, dim=-1) * torch.norm(text_features, dim=-1))\n",
    "        text_probs = (100.0 * dist).softmax(dim=-1)\n",
    "    \n",
    "    print(\"Image: \", filepath.split(\"/\")[-1])\n",
    "    print(f\"Label probs: {text_probs}\")\n",
    "    print(f\"Cosine similarity: {cos_sim}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9e61fc68371a3e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# CLIP: ViT-L-14 (Larger model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706d44cd35d4eab8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for filepath in lobster_0_files:\n",
    "    image = preprocess_l(Image.open(filepath)).unsqueeze(0)\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        image_features = model_l.encode_image(image)\n",
    "        text_features = model_l.encode_text(text_b)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        dist = image_features @ text_features.T\n",
    "        cos_sim = dist / (torch.norm(image_features, dim=-1) * torch.norm(text_features, dim=-1))\n",
    "        text_probs = (100.0 * dist).softmax(dim=-1)\n",
    "    \n",
    "    print(\"Image: \", filepath.split(\"/\")[-1])\n",
    "    print(f\"Label probs: {text_probs}\")\n",
    "    print(f\"Cosine similarity: {cos_sim}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbf17360a76f4c5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for filepath in lobster_1_files:\n",
    "    image = preprocess_l(Image.open(filepath)).unsqueeze(0)\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        image_features = model_l.encode_image(image)\n",
    "        text_features = model_l.encode_text(text_b)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        dist = image_features @ text_features.T\n",
    "        cos_sim = dist / (torch.norm(image_features, dim=-1) * torch.norm(text_features, dim=-1))\n",
    "        text_probs = (100.0 * dist).softmax(dim=-1)\n",
    "    \n",
    "    print(\"Image: \", filepath.split(\"/\")[-1])\n",
    "    print(f\"Label probs: {text_probs}\")\n",
    "    print(f\"Cosine similarity: {cos_sim}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb088b6377cb7d1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for filepath in lobster_2_files:\n",
    "    image = preprocess_l(Image.open(filepath)).unsqueeze(0)\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        image_features = model_l.encode_image(image)\n",
    "        text_features = model_l.encode_text(text_b)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        dist = image_features @ text_features.T\n",
    "        cos_sim = dist / (torch.norm(image_features, dim=-1) * torch.norm(text_features, dim=-1))\n",
    "        text_probs = (100.0 * dist).softmax(dim=-1)\n",
    "    \n",
    "    print(\"Image: \", filepath.split(\"/\")[-1])\n",
    "    print(f\"Label probs: {text_probs}\")\n",
    "    print(f\"Cosine similarity: {cos_sim}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for filepath in lobster_real_files:\n",
    "    image = preprocess_l(Image.open(filepath)).unsqueeze(0)\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        image_features = model_l.encode_image(image)\n",
    "        text_features = model_l.encode_text(text_b)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        dist = image_features @ text_features.T\n",
    "        cos_sim = dist / (torch.norm(image_features, dim=-1) * torch.norm(text_features, dim=-1))\n",
    "        text_probs = (100.0 * dist).softmax(dim=-1)\n",
    "    \n",
    "    print(\"Image: \", filepath.split(\"/\")[-1])\n",
    "    print(f\"Label probs: {text_probs}\")\n",
    "    print(f\"Cosine similarity: {cos_sim}\")\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a843047515ae1c80"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
