{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8f355948179877e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T19:29:02.280478Z",
     "start_time": "2024-03-28T19:29:02.273173Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'open_clip'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mopen_clip\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mipyplot\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'open_clip'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import open_clip\n",
    "import ipyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.pyplot import figure, imshow, axis\n",
    "from matplotlib.image import imread\n",
    "\n",
    "torch.set_printoptions(precision=3, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf62eb4b5ccce31",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T19:28:56.120130Z",
     "start_time": "2024-03-28T19:28:56.120055Z"
    }
   },
   "outputs": [],
   "source": [
    "def showImagesHorizontally(list_of_files):\n",
    "    fig = figure()\n",
    "    number_of_files = len(list_of_files)\n",
    "    for i in range(number_of_files):\n",
    "        a=fig.add_subplot(1,number_of_files,i+1)\n",
    "        image = imread(list_of_files[i])\n",
    "        # imshow(image, cmap='Greys_r')\n",
    "        imshow(image)\n",
    "        axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745863dbd0be0b37",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1964b4ebc2e979c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T19:28:56.128044Z",
     "start_time": "2024-03-28T19:28:56.126700Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c227598fc334509",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T19:28:56.166961Z",
     "start_time": "2024-03-28T19:28:56.156336Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'open_clip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mopen_clip\u001B[49m\u001B[38;5;241m.\u001B[39mlist_models()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'open_clip' is not defined"
     ]
    }
   ],
   "source": [
    "open_clip.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c4607bb3290ee1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_b, _, preprocess_b = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')\n",
    "tokenizer_b = open_clip.get_tokenizer('ViT-B-32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d15decfd0ec2d296",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T19:28:56.195222Z",
     "start_time": "2024-03-28T19:28:56.184357Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'open_clip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model_l, _, preprocess_l \u001B[38;5;241m=\u001B[39m \u001B[43mopen_clip\u001B[49m\u001B[38;5;241m.\u001B[39mcreate_model_and_transforms(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mViT-L-14-336\u001B[39m\u001B[38;5;124m'\u001B[39m, pretrained\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mopenai\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      2\u001B[0m tokenizer_l \u001B[38;5;241m=\u001B[39m open_clip\u001B[38;5;241m.\u001B[39mget_tokenizer(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mViT-B-32\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'open_clip' is not defined"
     ]
    }
   ],
   "source": [
    "model_l, _, preprocess_l = open_clip.create_model_and_transforms('ViT-L-14-336', pretrained='openai')\n",
    "tokenizer_l = open_clip.get_tokenizer('ViT-B-32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f110565a37ea9aaa",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T19:28:56.219870Z",
     "start_time": "2024-03-28T19:28:56.210526Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer_b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m text_b \u001B[38;5;241m=\u001B[39m \u001B[43mtokenizer_b\u001B[49m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma diagram\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma lobster\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma cat\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m      2\u001B[0m text_l \u001B[38;5;241m=\u001B[39m tokenizer_l([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma diagram\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma lobster\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma cat\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tokenizer_b' is not defined"
     ]
    }
   ],
   "source": [
    "text_b = tokenizer_b([\"a diagram\", \"a lobster\", \"a cat\"])\n",
    "text_l = tokenizer_l([\"a diagram\", \"a lobster\", \"a cat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa79572c2d6eda92",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Show Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f58dd2fcd5b5797",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<div style=\"display: flex; flex-direction: row;\">\n",
    "    <img src=\"./experiment_data/lobster_grayscale_0.png\" style=\"width: 200px; height: auto; margin-right: 10px;\">\n",
    "    <img src=\"./experiment_data/lobster_blue_0.png\" style=\"width: 200px; height: auto; margin-right: 10px;\">\n",
    "    <img src=\"./experiment_data/lobster_red_0.png\" style=\"width: 200px; height: auto; margin-right: 10px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30340b8745aa51d0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T19:28:56.220366Z",
     "start_time": "2024-03-28T19:28:56.220317Z"
    }
   },
   "outputs": [],
   "source": [
    "lobster_0_files = [\n",
    "    \"./experiment_data/lobster_grayscale_0.png\",\n",
    "    \"./experiment_data/lobster_blue_0.png\",\n",
    "    \"./experiment_data/lobster_red_0.png\"\n",
    "]\n",
    "\n",
    "lobster_1_files = [\n",
    "    \"./experiment_data/lobster_grayscale_1.png\",\n",
    "    \"./experiment_data/lobster_blue_1.png\",\n",
    "    \"./experiment_data/lobster_red_1.png\"\n",
    "]\n",
    "\n",
    "lobster_2_files = [\n",
    "    \"./experiment_data/lobster_grayscale_2.png\",\n",
    "    \"./experiment_data/lobster_blue_2.png\",\n",
    "    \"./experiment_data/lobster_red_2.png\"\n",
    "]\n",
    "\n",
    "lobster_real_files = [\n",
    "    \"./experiment_data/rlobster_0.png\",\n",
    "    \"./experiment_data/rlobster_1.png\",\n",
    "    \"./experiment_data/rlobster_2.png\"\n",
    "    \"./experiment_data/rlobster_3.png\"\n",
    "    \"./experiment_data/rlobster_4.png\"\n",
    "]\n",
    "\n",
    "# showImagesHorizontally(lobster_0_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212bfc737f603e3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Lobster (Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c877f8a49f5f260",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ipyplot.plot_images(lobster_0_files, max_images=3, img_width=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3856147d6014cc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Lobster (Front)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e59359a33825892c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T19:28:56.232677Z",
     "start_time": "2024-03-28T19:28:56.223490Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ipyplot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mipyplot\u001B[49m\u001B[38;5;241m.\u001B[39mplot_images(lobster_1_files, max_images\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, img_width\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m250\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ipyplot' is not defined"
     ]
    }
   ],
   "source": [
    "ipyplot.plot_images(lobster_1_files, max_images=3, img_width=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb30a979bebb7eaf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Lobster (Bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e0669616a90b48",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T19:28:56.233180Z",
     "start_time": "2024-03-28T19:28:56.233135Z"
    }
   },
   "outputs": [],
   "source": [
    "ipyplot.plot_images(lobster_2_files, max_images=3, img_width=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lobster Images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdfafda13c0a1dc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ipyplot.plot_images(lobster_real_files, max_images=5, img_width=250)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88caf55af643b7fd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in lobster_0_files:\n",
    "    image = preprocess_b(Image.open(filepath)).unsqueeze(0)\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        image_features = model_b.encode_image(image)\n",
    "        text_features = model_b.encode_text(text_b)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        dist = image_features @ text_features.T\n",
    "        cos_sim = dist / (torch.norm(image_features, dim=-1) * torch.norm(text_features, dim=-1))\n",
    "        text_probs = (100.0 * dist).softmax(dim=-1)\n",
    "    \n",
    "    print(\"Image: \", filepath.split(\"/\")[-1])\n",
    "    print(f\"Label probs: {text_probs}\")\n",
    "    print(f\"Cosine similarity: {cos_sim}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24356dfb22db8e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for filepath in lobster_1_files:\n",
    "    image = preprocess_b(Image.open(filepath)).unsqueeze(0)\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        image_features = model_b.encode_image(image)\n",
    "        text_features = model_b.encode_text(text_b)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        dist = image_features @ text_features.T\n",
    "        cos_sim = dist / (torch.norm(image_features, dim=-1) * torch.norm(text_features, dim=-1))\n",
    "        text_probs = (100.0 * dist).softmax(dim=-1)\n",
    "    \n",
    "    print(\"Image: \", filepath.split(\"/\")[-1])\n",
    "    print(f\"Label probs: {text_probs}\")\n",
    "    print(f\"Cosine similarity: {cos_sim}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8576599afde98f7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for filepath in lobster_2_files:\n",
    "    image = preprocess_b(Image.open(filepath)).unsqueeze(0)\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        image_features = model_b.encode_image(image)\n",
    "        text_features = model_b.encode_text(text_b)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        dist = image_features @ text_features.T\n",
    "        cos_sim = dist / (torch.norm(image_features, dim=-1) * torch.norm(text_features, dim=-1))\n",
    "        text_probs = (100.0 * dist).softmax(dim=-1)\n",
    "    \n",
    "    print(\"Image: \", filepath.split(\"/\")[-1])\n",
    "    print(f\"Label probs: {text_probs}\")\n",
    "    print(f\"Cosine similarity: {cos_sim}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9e61fc68371a3e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# CLIP: ViT-L-14 (Larger model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "706d44cd35d4eab8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T19:28:56.248490Z",
     "start_time": "2024-03-28T19:28:56.238055Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lobster_0_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m filepath \u001B[38;5;129;01min\u001B[39;00m \u001B[43mlobster_0_files\u001B[49m:\n\u001B[1;32m      2\u001B[0m     image \u001B[38;5;241m=\u001B[39m preprocess_l(Image\u001B[38;5;241m.\u001B[39mopen(filepath))\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad(), torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mautocast():\n",
      "\u001B[0;31mNameError\u001B[0m: name 'lobster_0_files' is not defined"
     ]
    }
   ],
   "source": [
    "for filepath in lobster_0_files:\n",
    "    image = preprocess_l(Image.open(filepath)).unsqueeze(0)\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        image_features = model_l.encode_image(image)\n",
    "        text_features = model_l.encode_text(text_b)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        dist = image_features @ text_features.T\n",
    "        cos_sim = dist / (torch.norm(image_features, dim=-1) * torch.norm(text_features, dim=-1))\n",
    "        text_probs = (100.0 * dist).softmax(dim=-1)\n",
    "    \n",
    "    print(\"Image: \", filepath.split(\"/\")[-1])\n",
    "    print(f\"Label probs: {text_probs}\")\n",
    "    print(f\"Cosine similarity: {cos_sim}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcbf17360a76f4c5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T19:28:56.286811Z",
     "start_time": "2024-03-28T19:28:56.274325Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lobster_1_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m filepath \u001B[38;5;129;01min\u001B[39;00m \u001B[43mlobster_1_files\u001B[49m:\n\u001B[1;32m      2\u001B[0m     image \u001B[38;5;241m=\u001B[39m preprocess_l(Image\u001B[38;5;241m.\u001B[39mopen(filepath))\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad(), torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mautocast():\n",
      "\u001B[0;31mNameError\u001B[0m: name 'lobster_1_files' is not defined"
     ]
    }
   ],
   "source": [
    "for filepath in lobster_1_files:\n",
    "    image = preprocess_l(Image.open(filepath)).unsqueeze(0)\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        image_features = model_l.encode_image(image)\n",
    "        text_features = model_l.encode_text(text_b)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        dist = image_features @ text_features.T\n",
    "        cos_sim = dist / (torch.norm(image_features, dim=-1) * torch.norm(text_features, dim=-1))\n",
    "        text_probs = (100.0 * dist).softmax(dim=-1)\n",
    "    \n",
    "    print(\"Image: \", filepath.split(\"/\")[-1])\n",
    "    print(f\"Label probs: {text_probs}\")\n",
    "    print(f\"Cosine similarity: {cos_sim}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb088b6377cb7d1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for filepath in lobster_2_files:\n",
    "    image = preprocess_l(Image.open(filepath)).unsqueeze(0)\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        image_features = model_l.encode_image(image)\n",
    "        text_features = model_l.encode_text(text_b)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        dist = image_features @ text_features.T\n",
    "        cos_sim = dist / (torch.norm(image_features, dim=-1) * torch.norm(text_features, dim=-1))\n",
    "        text_probs = (100.0 * dist).softmax(dim=-1)\n",
    "    \n",
    "    print(\"Image: \", filepath.split(\"/\")[-1])\n",
    "    print(f\"Label probs: {text_probs}\")\n",
    "    print(f\"Cosine similarity: {cos_sim}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for filepath in lobster_real_files:\n",
    "    image = preprocess_l(Image.open(filepath)).unsqueeze(0)\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        image_features = model_l.encode_image(image)\n",
    "        text_features = model_l.encode_text(text_b)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        dist = image_features @ text_features.T\n",
    "        cos_sim = dist / (torch.norm(image_features, dim=-1) * torch.norm(text_features, dim=-1))\n",
    "        text_probs = (100.0 * dist).softmax(dim=-1)\n",
    "    \n",
    "    print(\"Image: \", filepath.split(\"/\")[-1])\n",
    "    print(f\"Label probs: {text_probs}\")\n",
    "    print(f\"Cosine similarity: {cos_sim}\")\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a843047515ae1c80"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
